
在JDK8里面，去掉了分段锁，将锁的级别控制在了更细粒度的table元素级别，也就是说只需要锁住这个链表的head节点，并不会影响其他的table元素的读写，
好处在于并发的粒度更细，影响更小，从而并发效率更好，但不足之处在于并发扩容的时候，由于操作的table都是同一个，不像JDK7中分段控制，所以这里需
要等扩容完之后，所有的读写操作才能进行。




二、总结：

	1、ConcurrentHashMap是如何保证线程安全的？分别说一下JDK7和JDK8。
		JDK8：
			put操作：获取头节点操作：使用getObjectVolatile方法，支持Volatile内存语义。
				1、如果头节点为空，直接通过CAS进行添加【如果成功直接返回，不成功一直尝试】。
				2、如果头节点不为空，给头节点上锁，使用synchronized进行加锁。这个时候put操作就是串行执行了。进入锁以后，还是要判断头节点，如果头节点没有变化
				   才进行操作（双重加锁）。
				3、是否需要从链表到红黑树。在需要转换的时候也是会上锁的。转换之后通过cas更换头节点。
				###注意步骤2和步骤3锁的是同一个对象，所以在同一时刻2、3只有一个能执行。【分析场景：联系put两个，第一个先执行else;第二个先执行完第三步。这个时候第一步要怎么执行】###
				
	
		总结：头结点为空，直接CAS进行添加。如果不为空，使用的尾插法，把第一个元素上锁。

		
	
	2、头插法和尾插发
		JDK8之前使用的头插发，可以提高效率；JDK8及其以后使用的尾插发，安全考虑。
			
			
			
	3、添加元素以后才进行扩容为什么？	
			

			
			
			
			
			
			
			
			
			

#########################################
# 					初始化 				#
#########################################
/**
 * 初始化 
 */
public ConcurrentHashMap(int initialCapacity) {
	if (initialCapacity < 0) {
		throw new IllegalArgumentException();
	}
	
	// tableSizeFor返回给定容量的最小的2次幂。
	int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
	this.sizeCtl = cap;
}




###########  添加元素  #############
public V put(K key, V value) {
	return putVal(key, value, false);
}


final V putVal(K key, V value, boolean onlyIfAbsent) {
	// 不允许key/value为空。
	if (key == null || value == null) { 
		throw new NullPointerException();
	}
	
	// 计算key的hash值。
	int hash = spread(key.hashCode());
	int binCount = 0;
	
	// 不断循环。
	for (Node<K,V>[] tab = table;;) {
		// 头结点。
		Node<K,V> f; 
		
		// n：table数组的长度。 i:数据在数组上的位置。
		int n, i, fh;
		
		
		/**
		 * 第一次put元素时，初始化tabel。
		 */
		if (tab == null || (n = tab.length) == 0) {
			tab = initTable();
		
		
		/**
		 * 获取tab数组，第i位置的值，支持volatile语义。
		 * 如果头结点为null，直接添加。
		 */
		} else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
			
			// 直接进行添加。
			if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value, null))) {
				break;                   
			}
			
		/**
		 * static final int MOVED     = -1; 			表示该节点有线程处理过了
		 * static final int TREEBIN   = -2; 			表示判断到这个节点是一个树节点
		 * static final int RESERVED  = -3; 		
		 * static final int HASH_BITS = 0x7fffffff; 	普通节点哈希的可用位
		 * 如果该节点正在扩容，去协助扩容。
		 *
		 */
		} else if ((fh = f.hash) == MOVED) {
			tab = helpTransfer(tab, f);
			
		
		
		/**
		 * 使用synchronized进行上锁。
		 */
		} else {
			V oldVal = null;
			
			// 是一个对象锁。这里的节点可以理解为hash值相同组成的链表的头节点，锁的粒度为头节点。
			synchronized (f) {
				// 双重判断。
				if (tabAt(tab, i) == f) {
				
					// 普通节点。
					if (fh >= 0) {
						binCount = 1;
						for (Node<K,V> e = f;; ++binCount) {
							K ek;
							
							// 如果key已经存在，进行覆盖。
							if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
								oldVal = e.val;
								if (!onlyIfAbsent) {
									e.val = value;
								}
								break;
							}
							
							Node<K,V> pred = e;
							
							// 如果节点的后继节点为空，直接添加。
							if ((e = e.next) == null) {
								pred.next = new Node<K,V>(hash, key, value, null);
								break;
							}
						}
					
					// 如果获取的节点是一棵树。直接在
					} else if (f instanceof TreeBin) {
						Node<K,V> p;
						binCount = 2;
						// 向树中添加元素。
						if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
							oldVal = p.val;
							if (!onlyIfAbsent) {
								p.val = value;
							}
						}
					}
				}
			}
			
			// 从链表到树。
			if (binCount != 0) {
				if (binCount >= TREEIFY_THRESHOLD) {
					// 把链表转转成树的过程，这里面有一个加锁过程。同通过cas更换头节点。
					treeifyBin(tab, i);
				}
				
				if (oldVal != null) {
					return oldVal;
				}
				break;
			}
		}
	}
	
	// 检查是否需要扩容，或者是否正在扩容。如果需要扩容，就调用扩容方法，如果正在扩容，就帮助其扩容。
	addCount(1L, binCount);
	return null;
}

/**
 * 类似计算hash值。
 * h --> hashCode。
 */
static final int spread(int h) {

	// System.out.println(-8 >>> 2);  1073741822
	// 1000 0000 0000 0000 0000 1000  原码
	// 1111 1111 1111 1111 1111 0111  反码 -- 最高位不变，其他位取反
	// 1111 1111 1111 1111 1111 1000  补码 -- 反码 + 1
	// 0011 1111 1111 1111 1111 1110  结果
	
	// System.out.println(-8 >> 2);
	// 1000 0000 0000 0000 0000 1000  原码
	// 1111 1111 1111 1111 1111 0111  反码 -- 最高位不变，其他位取反
	// 1111 1111 1111 1111 1111 1000  补码 -- 反码 + 1
	// 1111 1111 1111 1111 1111 1110  结果
	// 1111 1111 1111 1111 1111 1101
	// 1000 0000 0000 0000 0000 0010  -2
	
	// HASH_BITS = 0x7fffffff;   ===>  0111 1111 1111 1111 1111 1111 1111 1111
	// ^ : 亦或运算
	// & : 按位与
	// >>> : 无符号右移，忽略符号位，空位都以0补齐。(不论正负,高位均补0)不区分符号。
	// >>  : 有符号右移。若正数,高位补0,负数,高位补1。
	return (h ^ (h >>> 16)) & HASH_BITS;
	
}


sizeCtr = 0  ：默认值；
sizeCtr = -1 ：表示Map正在初始化中；
sizeCtr = -N ：表示正在有N-1个线程进行扩容操作；
sizeCtr > 0  : 未初始化则表示初始化Map的大小，已初始化则表示【下次进行扩容操作的阈值】

// 初始化table
private final Node<K,V>[] initTable() {
	Node<K,V>[] tab; 
	int sc;
	
	// 循环直到初始化成功。
	while ((tab = table) == null || tab.length == 0) {
	
		// 让其他线程先执行，这就说明，有其他现在在执行初始化操作，或者扩容操作。
		if ((sc = sizeCtl) < 0) {
			Thread.yield();
			
		// 通过CAS将sizeCtl设置为-1。
		} else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
			try {
				if ((tab = table) == null || tab.length == 0) {
				
					// 设置默认容量。第一次都是16.
					int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
					
					// 初始化数组。
					Node<K,V>[] nt = (Node<K,V>[]) new Node<?,?>[n];
					table = tab = nt; 
					sc = n - (n >>> 2);   // (16 - 4) = 3n/4  也就是阈值。
				}
			} finally {
				sizeCtl = sc;
			}
			break;
		}
	}
	return tab;
}


static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
	// 获取obj对象中offset偏移地址对应的object型field的值,支持volatile load语义。
	return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}

// 原子操作，支持cas
static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v) {
	return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
}



#########################################
#					协助扩容			#
#########################################
/**
 * 协助扩容。
 */
final Node<K,V>[] helpTransfer(Node<K,V>[] tab, Node<K,V> f) {
	Node<K,V>[] nextTab; 
	int sc;
	
	if (tab != null && (f instanceof ForwardingNode) && (nextTab = ((ForwardingNode<K,V>)f).nextTable) != null) {
		int rs = resizeStamp(tab.length);
		while (nextTab == nextTable && table == tab && (sc = sizeCtl) < 0) {
			if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex <= 0) {
				break;
			}
			
			if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
				transfer(tab, nextTab);
				break;
			}
		}
		return nextTab;
	}
	return table;
}



static final int resizeStamp(int n) {
	return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));
}

// 从链表到树。table为node数组，index为数组中的位置。
private final void treeifyBin(Node<K,V>[] tab, int index) {

	Node<K,V> b; 
	int n, sc;
	
	if (tab != null) {
		// 数组长度小于最小数容量64。
		if ((n = tab.length) < MIN_TREEIFY_CAPACITY) {
			tryPresize(n << 1);
						
		// 获取对应的头元素，并锁定对应的头元素。
		} else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {
			synchronized (b) {
				// 再次判断。类似双层加锁。
				if (tabAt(tab, index) == b) {
					// hb：头节点；tl：前驱节点。
					TreeNode<K,V> hd = null, tl = null;
					
					// 循环节点。
					for (Node<K,V> e = b; e != null; e = e.next) {
						TreeNode<K,V> p = new TreeNode<K,V>(e.hash, e.key, e.val, null, null);
						// p的前驱是否为null。
						if ((p.prev = tl) == null) {
							hd = p;
						} else {
							tl.next = p;
						}
						tl = p;
					}
					
					// 原子操作，把table数组对应位置上的节点（也就是所谓的头节点）更改为tree的根节点。
					setTabAt(tab, index, new TreeBin<K,V>(hd));
				}
			}
		}
	}
}

// 扩大两倍的table长度。
private final void tryPresize(int size) {
	// >>>无符号；>>有符号。//如果大小为MAXIMUM_CAPACITY最大总量的一半，那么直接扩容为MAXIMUM_CAPACITY，否则计算最小幂次方
	// 如果size：16；16 + 8 + 1 = 25 == 32
	int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size >>> 1) + 1);
	int sc;
	
	while ((sc = sizeCtl) >= 0) {
		Node<K,V>[] tab = table; int n;
		if (tab == null || (n = tab.length) == 0) {
			n = (sc > c) ? sc : c;
			if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
				try {
					if (table == tab) {
						@SuppressWarnings("unchecked")
						Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
						table = nt;
						sc = n - (n >>> 2);
					}
				} finally {
					sizeCtl = sc;
				}
			}
		} else if (c <= sc || n >= MAXIMUM_CAPACITY) {
			break;
		} else if (tab == table) {
			int rs = resizeStamp(n);
			if (sc < 0) {
				Node<K,V>[] nt;
				if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex <= 0) {
					break;
				}
				if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
					transfer(tab, nt);
				}
			} else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)) {
				transfer(tab, null);
			}
		}
	}
}




/** 
 * check：-1是删除，1是链表，2是红黑树
 * 检查是否需要扩容，或者是否正在扩容。如果需要扩容，就调用扩容方法，如果正在扩容，就帮助其扩容。
 */
private final void addCount(long x, int check) {
	CounterCell[] as; 
	long b, s;
	
	// counterCells不为null 【或者】 更新baseCount失败
	if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
		CounterCell a; 
		long v; 
		int m;
		
		// uncontended：无竞争。
		boolean uncontended = true;
		
		// 如果计数盒子是空（尚未出现并发） 如果随机取余一个数组位置为空或者修改这个槽位的变量失败（出现并发了）
		if (as == null || (m = as.length - 1) < 0 || (a = as[ThreadLocalRandom.getProbe() & m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
			fullAddCount(x, uncontended);
			return;
		}
		if (check <= 1) {
			return;
		}
		s = sumCount();
	}
	
	//  如果check值大于等于0 则需要检验是否需要进行扩容操作，即为可能出现扩容的情况，例如putVal方法中的调用
	if (check >= 0) {
		Node<K,V>[] tab, nt; 
		int n, sc;
		
		/**
		 * 检查当前集合元素个数s是否达到扩容阈值 sizeCtl，扩容时sizeCtl为负数，依旧成立，同时还得满足数组非空且数组长度不能大于允许的数组最大长度.
		 * 这个while循环除了判断是否达到阈值从而进行扩容操作之外还有一个作用就是当一条线程完成自己的迁移任务后，如果集合还在扩容，则会继续循环，继
		 * 续加入扩容大军，申请后面的迁移任务。
		 */
		while (s >= (long)(sc = sizeCtl) && (tab = table) != null && (n = tab.length) < MAXIMUM_CAPACITY) {
			
			int rs = resizeStamp(n);
			
			// sc < 0 说明集合正在扩容当中
			if (sc < 0) {
			
				// 判断扩容是否结束或者并发扩容线程数是否已达最大值，如果是的话直接结束while循环.
				if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex <= 0) {
					break;
				}
				
				// 扩容还未结束，并且允许扩容线程加入，此时加入扩容大军中.
				if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
					transfer(tab, nt);
				}
				
			/**
			 * 如果集合还未处于扩容状态中，则进入扩容方法，并首先初始化nextTab数组，也就是新数组。(rs << RESIZE_STAMP_SHIFT) + 2为首个扩容线程所设置的特定值，
			 * 后面扩容时会根据线程是否为这个值来确定是否为最后一个线程。
			 */
			} else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)) {
				transfer(tab, null);
			}
			
			
			s = sumCount();
		}
	}
}

/**
 * 返回与扩容有关的一个生成戳rs，每次新的扩容，都有一个不同的n，这个生成戳就是根据n来计算出来的一个数字，n不同，这个数字也不同
 * 另外还得保证 rs << RESIZE_STAMP_SHIFT 必须是负数
 * 这个方法的返回值，当且仅当 RESIZE_STAMP_SIZE = 32时为负数
 * 但是b = 32时MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1 = 0，这一点很奇怪
 */
static final int resizeStamp(int n) {
    return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));
}


private final void fullAddCount(long x, boolean wasUncontended) {
	int h;
	if ((h = ThreadLocalRandom.getProbe()) == 0) {
		// 强制初始化
		ThreadLocalRandom.localInit(); 
		h = ThreadLocalRandom.getProbe();
		wasUncontended = true;
	}
	
	// 如果最后一个插槽非空则为真
	boolean collide = false;
	for (;;) {
		CounterCell[] as; 
		CounterCell a; 
		int n; 
		long v;
		
		if ((as = counterCells) != null && (n = as.length) > 0) {
			if ((a = as[(n - 1) & h]) == null) {
				if (cellsBusy == 0) {            // Try to attach new Cell
					CounterCell r = new CounterCell(x); // Optimistic create
					if (cellsBusy == 0 &&
						U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
						boolean created = false;
						try {               // Recheck under lock
							CounterCell[] rs; int m, j;
							if ((rs = counterCells) != null &&
								(m = rs.length) > 0 &&
								rs[j = (m - 1) & h] == null) {
								rs[j] = r;
								created = true;
							}
						} finally {
							cellsBusy = 0;
						}
						if (created)
							break;
						continue;           		// Slot is now non-empty
					}
				}
				collide = false;
			} else if (!wasUncontended) {       	// CAS already known to fail
				wasUncontended = true;      		// Continue after rehash
			} else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) {
				break;
			} else if (counterCells != as || n >= NCPU) {
				collide = false;            		// At max size or stale
			} else if (!collide) {
				collide = true;
			} else if (cellsBusy == 0 &&  U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
				try {
					if (counterCells == as) {		// Expand table unless stale
						CounterCell[] rs = new CounterCell[n << 1];
						for (int i = 0; i < n; ++i) {
							rs[i] = as[i];
						}
						counterCells = rs;
					}
				} finally {
					cellsBusy = 0;
				}
				collide = false;
				continue;                   		// Retry with expanded table
			}
			h = ThreadLocalRandom.advanceProbe(h);
		}
		else if (cellsBusy == 0 && counterCells == as && U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
			boolean init = false;
			try {                          			// Initialize table
				if (counterCells == as) {
					CounterCell[] rs = new CounterCell[2];
					rs[h & 1] = new CounterCell(x);
					counterCells = rs;
					init = true;
				}
			} finally {
				cellsBusy = 0;
			}
			if (init) {
				break;
			}
		} else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) {
			break;                          // Fall back on using base
		}
	}
}



/**
 * https://blog.csdn.net/ZOKEKAI/article/details/90051567
 */
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
	int n = tab.length, stride;
	
	
	/**
	 * NCPU：获取计算机的CPU核数。
	 * 
	 * 计算每条线程处理的桶个数，每条线程处理的桶数量一样，如果CPU为单核，则使用一条线程处理所有桶。每条线程至少处理16个桶，
	 * 如果计算出来的结果少于16，则一条线程处理16个桶。
	 */
	if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE) {
		stride = MIN_TRANSFER_STRIDE;
	}
	
	/**
	 * 初始化新数组(原数组长度的2倍)。nextTab为新数组。
	 */
	if (nextTab == null) {           
		try {
			Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
			nextTab = nt;
		} catch (Throwable ex) { 
			sizeCtl = Integer.MAX_VALUE;
			return;
		}
		nextTable = nextTab;
		
		//将transferIndex指向最右边的桶，也就是数组索引下标最大的位置。
		transferIndex = n;
	}
	
	/**
	 * 新建一个占位对象，该占位对象的hash值为-1该占位对象存在时表示集合正在扩容状态，key、value、next 属性均为null，nextTable属性指向扩容后
	 * 的数组该占位对象主要有两个用途：
	 *		1、占位作用，用于标识数组该位置的桶已经迁移完毕，处于扩容中的状态。
	 *		2、作为一个转发的作用，扩容期间如果遇到查询操作，遇到转发节点，会把该查询操作转发到新的数组上去，不会阻塞查询操作。
	 */
	int nextn = nextTab.length;
	ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
	
	// 该标识用于控制是否继续处理下一个桶，为true则表示已经处理完当前桶，可以继续迁移下一个桶的数据。
	boolean advance = true;
	
	// 该标识用于控制扩容何时结束，该标识还有一个用途是最后一个扩容线程会负责重新检查一遍数组查看是否有遗漏的桶
	boolean finishing = false; 
	
	
	/**
	 * 这个循环用于处理一个stride长度的任务，i后面会被赋值为该stride内最大的下标，而bound后面会被赋值为该stride内最小的下标。通过循环不断减小i的值，
	 * 从右往左依次迁移桶上面的数据，直到i小于bound时结束该次长度为stride的迁移任务。结束这次的任务后会通过外层addCount、helpTransfer、tryPresize
	 * 方法的 while 循环达到继续领取其他任务的效果。
	 */
	for (int i = 0, bound = 0;;) {
		Node<K,V> f; int fh;
		
		while (advance) {
			int nextIndex, nextBound;
			
			// 每处理完一个hash桶就将bound进行减1操作。
			if (--i >= bound || finishing) {
				advance = false;
			
			
			// transferIndex<= 0说明数组的hash桶已被线程分配完毕，没有了待分配的hash桶，将i设置为-1，后面的代码根据这个数值退出当前线的扩容操作。
			} else if ((nextIndex = transferIndex) <= 0) {
				i = -1;
				advance = false;
			
			
			//只有首次进入for循环才会进入这个判断里面去，设置bound和i的值，也就是领取到的迁移任务的数组区间。
			} else if (U.compareAndSwapInt(this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex > stride ? nextIndex - stride : 0))) {
				bound = nextBound;
				i = nextIndex - 1;
				advance = false;
			}
		}
		
		if (i < 0 || i >= n || i + n >= nextn) {
			int sc;
			
			// 扩容结束后做后续工作，将nextTable设置为null，表示扩容已结束，将table指向新数组，sizeCtl设置为扩容阈值。
			if (finishing) {
				nextTable = null;
				table = nextTab;
				sizeCtl = (n << 1) - (n >>> 1);
				return;
			}
			
			// 每当一条线程扩容结束就会更新一次sizeCtl的值，进行减1操作。
			if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
			
				// (sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT 成立，说明该线程不是扩容大军里面的最后一条线程，直接return回到上层while循环
				if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT) {
					return;
				}
				
				//(sc - 2) == resizeStamp(n) << RESIZE_STAMP_SHIFT 说明这条线程是最后一条扩容线程
                //之所以能用这个来判断是否是最后一条线程，因为第一条扩容线程进行了如下操作：
                //    U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)
                //除了修改结束标识之外，还得设置 i = n; 以便重新检查一遍数组，防止有遗漏未成功迁移的桶
				finishing = advance = true;
				i = n;
			}
		} else if ((f = tabAt(tab, i)) == null) {
			advance = casTabAt(tab, i, null, fwd);
		} else if ((fh = f.hash) == MOVED) {
			advance = true;
		} else {
			synchronized (f) {
				if (tabAt(tab, i) == f) {
					Node<K,V> ln, hn;
					if (fh >= 0) {
						int runBit = fh & n;
						Node<K,V> lastRun = f;
						for (Node<K,V> p = f.next; p != null; p = p.next) {
							int b = p.hash & n;
							if (b != runBit) {
								runBit = b;
								lastRun = p;
							}
						}
						
						if (runBit == 0) {
							ln = lastRun;
							hn = null;
						} else {
							hn = lastRun;
							ln = null;
						}
						
						for (Node<K,V> p = f; p != lastRun; p = p.next) {
							int ph = p.hash; K pk = p.key; V pv = p.val;
							if ((ph & n) == 0) {
								ln = new Node<K,V>(ph, pk, pv, ln);
							} else {
								hn = new Node<K,V>(ph, pk, pv, hn);
							}
						}
						setTabAt(nextTab, i, ln);
						setTabAt(nextTab, i + n, hn);
						setTabAt(tab, i, fwd);
						advance = true;
					} else if (f instanceof TreeBin) {
						TreeBin<K,V> t = (TreeBin<K,V>)f;
						TreeNode<K,V> lo = null, loTail = null;
						TreeNode<K,V> hi = null, hiTail = null;
						int lc = 0, hc = 0;
						for (Node<K,V> e = t.first; e != null; e = e.next) {
							int h = e.hash;
							TreeNode<K,V> p = new TreeNode<K,V>(h, e.key, e.val, null, null);
							if ((h & n) == 0) {
								if ((p.prev = loTail) == null){
									lo = p;
								} else {
									loTail.next = p;
								}
								loTail = p;
								++lc;
							} else {
								if ((p.prev = hiTail) == null) {
									hi = p;
								} else {
									hiTail.next = p;
								}
								hiTail = p;
								++hc;
							}
						}
						
						ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin<K,V>(lo) : t;
						hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin<K,V>(hi) : t;
						setTabAt(nextTab, i, ln);
						setTabAt(nextTab, i + n, hn);
						setTabAt(tab, i, fwd);
						advance = true;
					}
				}
			}
		}
	}
}






##################################   get过程。  ########################################
// get是没有锁的。
public V get(Object key) {
	Node<K,V>[] tab; 
	Node<K,V> e, p; 
	
	// n：数组长度，eh：节点的hash值，
	int n, eh; K ek;
	
	int h = spread(key.hashCode());
	
	// 把tabel赋值给tab。把长度赋值给n。e为获取对应key的节点。
	if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) {
		// 直接返回。
		if ((eh = e.hash) == h) {
			if ((ek = e.key) == key || (ek != null && key.equals(ek))) {
				return e.val;
			}
		// 如果头结点的hash小于0，说明正在扩容，或者该位置是红黑树。
		} else if (eh < 0) {
			return (p = e.find(h, key)) != null ? p.val : null;
		}
		
		while ((e = e.next) != null) {
			if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
				return e.val;
			}
		}
	}
	
	return null;
}


############################################################        size()      ########################################################
/**
 *
 */
public int size() {
	long n = sumCount();
	return ((n < 0L) ? 0 : (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);
}

/**
 *
 */
final long sumCount() {
	CounterCell[] as = counterCells; CounterCell a;
	long sum = baseCount;
	if (as != null) {
		for (int i = 0; i < as.length; ++i) {
			if ((a = as[i]) != null) {
				sum += a.value;
			}
		}
	}
	return sum;
}
