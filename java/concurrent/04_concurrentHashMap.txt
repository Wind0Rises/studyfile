在JDK8里面，去掉了分段锁，将锁的级别控制在了更细粒度的table元素级别，也就是说只需要锁住这个链表的head节点，并不会影响其他的table元素的读写，
好处在于并发的粒度更细，影响更小，从而并发效率更好，但不足之处在于并发扩容的时候，由于操作的table都是同一个，不像JDK7中分段控制，所以这里需
要等扩容完之后，所有的读写操作才能进行。


1、ConcurrentHashMap是如何保证线程安全的？分别说一下JDK7和JDK8。
	JDK8：
		put操作：获取头节点操作：使用getObjectVolatile方法，支持Volatile内存语义。
			1、如果头节点为空，直接通过compareAndSwapObject进行添加【如果成功直接返回，不成功一直尝试】。
			2、如果头节点不为空，给头节点上锁。这个时候put操作就是串行执行了。进入锁以后，还是要判断头节点，如果头节点没有变化才进行操作（双重加锁）。
			3、是否需要从链表到红黑树。在需要转换的时候也是会上锁的。转换之后通过cas更换头节点。
			###注意步骤2和步骤3锁的是同一个对象，所以在同一时刻2、3只有一个能执行。【分析场景：联系put两个，第一个先执行else;第二个先执行完第三步。这个时候第一步要怎么执行】###
			
	
	总结：头结点为空，直接CAS进行添加。如果不为空，使用的尾插法，把第一个元素上锁。
			
			
			

##########   初始化  ########
public ConcurrentHashMap(int initialCapacity) {
	if (initialCapacity < 0) {
		throw new IllegalArgumentException();
	}
	
	// tableSizeFor返回给定容量的最小的2次幂。
	int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
	this.sizeCtl = cap;
}




###########  添加元素  #############
public V put(K key, V value) {
	return putVal(key, value, false);
}


final V putVal(K key, V value, boolean onlyIfAbsent) {
	// 不允许key/value为空。
	if (key == null || value == null) { 
		throw new NullPointerException();
	}
	
	// 计算key的hash值。
	int hash = spread(key.hashCode());
	int binCount = 0;
	
	// 不断循环。
	for (Node<K,V>[] tab = table;;) {
		// 头结点。
		Node<K,V> f; 
		
		// n：table数组的长度。 i:数据在数组上的位置。
		int n, i, fh;
		
		// 第一次put元素时，初始化tabel。
		if (tab == null || (n = tab.length) == 0) {
			tab = initTable();
		
		// 获取tab数组，第i位置的值，支持volatile语义。
		// 如果头结点为null，直接添加。
		} else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
			
			// 直接进行添加。
			if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value, null))) {
				break;                   
			}
			
		// static final int MOVED     = -1; 			表示该节点有线程处理过了
		// static final int TREEBIN   = -2; 			表示判断到这个节点是一个树节点
		// static final int RESERVED  = -3; 		
		// static final int HASH_BITS = 0x7fffffff; 	普通节点哈希的可用位
		// 如果该节点正在扩容，去协助扩容。
		} else if ((fh = f.hash) == MOVED) {
			tab = helpTransfer(tab, f);
			
		// 
		} else {
			V oldVal = null;
			
			// 是一个对象锁。这里的节点可以理解为hash值相同组成的链表的头节点，锁的粒度为头节点。
			synchronized (f) {
				// 双重判断。
				if (tabAt(tab, i) == f) {
				
					// 普通节点。
					if (fh >= 0) {
						binCount = 1;
						for (Node<K,V> e = f;; ++binCount) {
							K ek;
							
							// 如果key已经存在，进行覆盖。
							if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
								oldVal = e.val;
								if (!onlyIfAbsent) {
									e.val = value;
								}
								break;
							}
							
							Node<K,V> pred = e;
							
							// 如果节点的后继节点为空，直接添加。
							if ((e = e.next) == null) {
								pred.next = new Node<K,V>(hash, key, value, null);
								break;
							}
						}
					
					// 如果获取的节点是一棵树。直接在
					} else if (f instanceof TreeBin) {
						Node<K,V> p;
						binCount = 2;
						// 向树中添加元素。
						if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
							oldVal = p.val;
							if (!onlyIfAbsent) {
								p.val = value;
							}
						}
					}
				}
			}
			
			// 从链表到树。
			if (binCount != 0) {
				if (binCount >= TREEIFY_THRESHOLD) {
					// 把链表转转成树的过程，这里面有一个加锁过程。同通过cas更换头节点。
					treeifyBin(tab, i);
				}
				
				if (oldVal != null) {
					return oldVal;
				}
				break;
			}
		}
	}
	
	// 检查是否需要扩容，或者是否正在扩容。如果需要扩容，就调用扩容方法，如果正在扩容，就帮助其扩容。
	addCount(1L, binCount);
	return null;
}

/**
 * 类似计算hash值。
 * h --> hashCode。
 */
static final int spread(int h) {

	// System.out.println(-8 >>> 2);  1073741822
	// 1000 0000 0000 0000 0000 1000  原码
	// 1111 1111 1111 1111 1111 0111  反码 -- 最高位不变，其他位取反
	// 1111 1111 1111 1111 1111 1000  补码 -- 反码 + 1
	// 0011 1111 1111 1111 1111 1110  结果
	
	// System.out.println(-8 >> 2);
	// 1000 0000 0000 0000 0000 1000  原码
	// 1111 1111 1111 1111 1111 0111  反码 -- 最高位不变，其他位取反
	// 1111 1111 1111 1111 1111 1000  补码 -- 反码 + 1
	// 1111 1111 1111 1111 1111 1110  结果
	// 1111 1111 1111 1111 1111 1101
	// 1000 0000 0000 0000 0000 0010  -2
	
	// HASH_BITS = 0x7fffffff;   ===>  0111 1111 1111 1111 1111 1111 1111 1111
	// ^ : 亦或运算
	// & : 按位与
	// >>> : 无符号右移，忽略符号位，空位都以0补齐。(不论正负,高位均补0)不区分符号。
	// >>  : 有符号右移。若正数,高位补0,负数,高位补1。
	return (h ^ (h >>> 16)) & HASH_BITS;
	
}


sizeCtr = 0  ：默认值；
sizeCtr = -1 ：表示Map正在初始化中；
sizeCtr = -N ：表示正在有N-1个线程进行扩容操作；
sizeCtr > 0  : 未初始化则表示初始化Map的大小，已初始化则表示【下次进行扩容操作的阈值】

// 初始化table
private final Node<K,V>[] initTable() {
	Node<K,V>[] tab; 
	int sc;
	
	// 循环直到初始化成功。
	while ((tab = table) == null || tab.length == 0) {
	
		// 让其他线程先执行，这就说明，有其他现在在执行初始化操作，或者扩容操作。
		if ((sc = sizeCtl) < 0) {
			Thread.yield();
			
		// 通过CAS将sizeCtl设置为-1。
		} else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
			try {
				if ((tab = table) == null || tab.length == 0) {
				
					// 设置默认容量。第一次都是16.
					int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
					
					// 初始化数组。
					Node<K,V>[] nt = (Node<K,V>[]) new Node<?,?>[n];
					table = tab = nt; 
					sc = n - (n >>> 2);   // (16 - 4) = 3n/4  也就是阈值。
				}
			} finally {
				sizeCtl = sc;
			}
			break;
		}
	}
	return tab;
}


static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
	// 获取obj对象中offset偏移地址对应的object型field的值,支持volatile load语义。
	return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}

// 原子操作，支持cas
static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v) {
	return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
}


// 协助扩容。
final Node<K,V>[] helpTransfer(Node<K,V>[] tab, Node<K,V> f) {
	Node<K,V>[] nextTab; 
	int sc;
	
	if (tab != null && (f instanceof ForwardingNode) && (nextTab = ((ForwardingNode<K,V>)f).nextTable) != null) {
		int rs = resizeStamp(tab.length);
		while (nextTab == nextTable && table == tab && (sc = sizeCtl) < 0) {
			if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex <= 0) {
				break;
			}
			
			if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
				transfer(tab, nextTab);
				break;
			}
		}
		return nextTab;
	}
	return table;
}



static final int resizeStamp(int n) {
	return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));
}

// 从链表到树。table为node数组，index为数组中的位置。
private final void treeifyBin(Node<K,V>[] tab, int index) {

	Node<K,V> b; 
	int n, sc;
	
	if (tab != null) {
		// 数组长度小于最小数容量64。
		if ((n = tab.length) < MIN_TREEIFY_CAPACITY) {
			tryPresize(n << 1);
						
		// 获取对应的头元素，并锁定对应的头元素。
		} else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {
			synchronized (b) {
				// 再次判断。类似双层加锁。
				if (tabAt(tab, index) == b) {
					// hb：头节点；tl：前驱节点。
					TreeNode<K,V> hd = null, tl = null;
					
					// 循环节点。
					for (Node<K,V> e = b; e != null; e = e.next) {
						TreeNode<K,V> p = new TreeNode<K,V>(e.hash, e.key, e.val, null, null);
						// p的前驱是否为null。
						if ((p.prev = tl) == null) {
							hd = p;
						} else {
							tl.next = p;
						}
						tl = p;
					}
					
					// 原子操作，把table数组对应位置上的节点（也就是所谓的头节点）更改为tree的根节点。
					setTabAt(tab, index, new TreeBin<K,V>(hd));
				}
			}
		}
	}
}

// 扩大两倍的table长度。
private final void tryPresize(int size) {
	// >>>无符号；>>有符号。//如果大小为MAXIMUM_CAPACITY最大总量的一半，那么直接扩容为MAXIMUM_CAPACITY，否则计算最小幂次方
	// 如果size：16；16 + 8 + 1 = 25 == 32
	int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size >>> 1) + 1);
	int sc;
	
	while ((sc = sizeCtl) >= 0) {
		Node<K,V>[] tab = table; int n;
		if (tab == null || (n = tab.length) == 0) {
			n = (sc > c) ? sc : c;
			if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
				try {
					if (table == tab) {
						@SuppressWarnings("unchecked")
						Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
						table = nt;
						sc = n - (n >>> 2);
					}
				} finally {
					sizeCtl = sc;
				}
			}
		} else if (c <= sc || n >= MAXIMUM_CAPACITY) {
			break;
		} else if (tab == table) {
			int rs = resizeStamp(n);
			if (sc < 0) {
				Node<K,V>[] nt;
				if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex <= 0) {
					break;
				}
				if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
					transfer(tab, nt);
				}
			} else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)) {
				transfer(tab, null);
			}
		}
	}
}

/** 
 * 检查是否需要扩容，或者是否正在扩容。如果需要扩容，就调用扩容方法，如果正在扩容，就帮助其扩容。
 */
 
 // check：-1是删除，1是链表，2是红黑树
private final void addCount(long x, int check) {
	CounterCell[] as; 
	long b, s;
	
	// counterCells不为null 【或者】 更新baseCount失败
	if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
		CounterCell a; 
		long v; 
		int m;
		
		// uncontended：无竞争。
		boolean uncontended = true;
		
		// 如果计数盒子是空（尚未出现并发） 如果随机取余一个数组位置为空或者修改这个槽位的变量失败（出现并发了）
		if (as == null || (m = as.length - 1) < 0 || (a = as[ThreadLocalRandom.getProbe() & m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
			fullAddCount(x, uncontended);
			return;
		}
		if (check <= 1) {
			return;
		}
		s = sumCount();
	}
	
	//  如果check值大于等于0 则需要检验是否需要进行扩容操作，即为可能出现扩容的情况，例如putVal方法中的调用
	if (check >= 0) {
		Node<K,V>[] tab, nt; 
		int n, sc;
		
		// 检查当前集合元素个数 s 是否达到扩容阈值 sizeCtl ，扩容时 sizeCtl 为负数，依旧成立，同时还得满足数组非空且
		// 数组长度不能大于允许的数组最大长度这两个条件才能继续。。这个 while 循环除了判断是否达到阈值从而进行扩容操作
		// 之外还有一个作用就是当一条线程完成自己的迁移任务后，如果集合还在扩容，则会继续循环，继续加入扩容大军，申请后面的迁移任务
		while (s >= (long)(sc = sizeCtl) && (tab = table) != null && (n = tab.length) < MAXIMUM_CAPACITY) {
			
			int rs = resizeStamp(n);
			
			// sc < 0 说明集合正在扩容当中
			if (sc < 0) {
			
				// 判断扩容是否结束或者并发扩容线程数是否已达最大值，如果是的话直接结束while循环.
				if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex <= 0) {
					break;
				}
				
				// 扩容还未结束，并且允许扩容线程加入，此时加入扩容大军中
				if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) {
					transfer(tab, nt);
				}
				
			// 如果集合还未处于扩容状态中，则进入扩容方法，并首先初始化 nextTab 数组，也就是新数组。(rs << RESIZE_STAMP_SHIFT) + 2 为首个扩容线程所设置的特定值，
			// 后面扩容时会根据线程是否为这个值来确定是否为最后一个线程。
			} else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs << RESIZE_STAMP_SHIFT) + 2)) {
				transfer(tab, null);
			}
			
			
			s = sumCount();
		}
	}
}

/**
 * 返回与扩容有关的一个生成戳rs，每次新的扩容，都有一个不同的n，这个生成戳就是根据n来计算出来的一个数字，n不同，这个数字也不同
 * 另外还得保证 rs << RESIZE_STAMP_SHIFT 必须是负数
 * 这个方法的返回值，当且仅当 RESIZE_STAMP_SIZE = 32时为负数
 * 但是b = 32时MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1 = 0，这一点很奇怪
 */
static final int resizeStamp(int n) {
    return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));
}


private final void fullAddCount(long x, boolean wasUncontended) {
	int h;
	if ((h = ThreadLocalRandom.getProbe()) == 0) {
		// 强制初始化
		ThreadLocalRandom.localInit(); 
		h = ThreadLocalRandom.getProbe();
		wasUncontended = true;
	}
	
	// 如果最后一个插槽非空则为真
	boolean collide = false;
	for (;;) {
		CounterCell[] as; 
		CounterCell a; 
		int n; 
		long v;
		
		if ((as = counterCells) != null && (n = as.length) > 0) {
			if ((a = as[(n - 1) & h]) == null) {
				if (cellsBusy == 0) {            // Try to attach new Cell
					CounterCell r = new CounterCell(x); // Optimistic create
					if (cellsBusy == 0 &&
						U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
						boolean created = false;
						try {               // Recheck under lock
							CounterCell[] rs; int m, j;
							if ((rs = counterCells) != null &&
								(m = rs.length) > 0 &&
								rs[j = (m - 1) & h] == null) {
								rs[j] = r;
								created = true;
							}
						} finally {
							cellsBusy = 0;
						}
						if (created)
							break;
						continue;           		// Slot is now non-empty
					}
				}
				collide = false;
			} else if (!wasUncontended) {       	// CAS already known to fail
				wasUncontended = true;      		// Continue after rehash
			} else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) {
				break;
			} else if (counterCells != as || n >= NCPU) {
				collide = false;            		// At max size or stale
			} else if (!collide) {
				collide = true;
			} else if (cellsBusy == 0 &&  U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
				try {
					if (counterCells == as) {		// Expand table unless stale
						CounterCell[] rs = new CounterCell[n << 1];
						for (int i = 0; i < n; ++i) {
							rs[i] = as[i];
						}
						counterCells = rs;
					}
				} finally {
					cellsBusy = 0;
				}
				collide = false;
				continue;                   		// Retry with expanded table
			}
			h = ThreadLocalRandom.advanceProbe(h);
		}
		else if (cellsBusy == 0 && counterCells == as && U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
			boolean init = false;
			try {                          			// Initialize table
				if (counterCells == as) {
					CounterCell[] rs = new CounterCell[2];
					rs[h & 1] = new CounterCell(x);
					counterCells = rs;
					init = true;
				}
			} finally {
				cellsBusy = 0;
			}
			if (init) {
				break;
			}
		} else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x)) {
			break;                          // Fall back on using base
		}
	}
}

/**
 *
 */
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
	int n = tab.length, stride;
	
	if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE) {
		stride = MIN_TRANSFER_STRIDE;
	}
	if (nextTab == null) {           
		try {
			Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
			nextTab = nt;
		} catch (Throwable ex) {      // try to cope with OOME
			sizeCtl = Integer.MAX_VALUE;
			return;
		}
		nextTable = nextTab;
		transferIndex = n;
	}
	int nextn = nextTab.length;
	ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
	boolean advance = true;
	boolean finishing = false; 
	for (int i = 0, bound = 0;;) {
		Node<K,V> f; int fh;
		while (advance) {
			int nextIndex, nextBound;
			if (--i >= bound || finishing) {
				advance = false;
			} else if ((nextIndex = transferIndex) <= 0) {
				i = -1;
				advance = false;
			} else if (U.compareAndSwapInt(this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex > stride ? nextIndex - stride : 0))) {
				bound = nextBound;
				i = nextIndex - 1;
				advance = false;
			}
		}
		if (i < 0 || i >= n || i + n >= nextn) {
			int sc;
			if (finishing) {
				nextTable = null;
				table = nextTab;
				sizeCtl = (n << 1) - (n >>> 1);
				return;
			}
			if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
				if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT) {
					return;
				}
				finishing = advance = true;
				i = n;
			}
		} else if ((f = tabAt(tab, i)) == null) {
			advance = casTabAt(tab, i, null, fwd);
		} else if ((fh = f.hash) == MOVED) {
			advance = true;
		} else {
			synchronized (f) {
				if (tabAt(tab, i) == f) {
					Node<K,V> ln, hn;
					if (fh >= 0) {
						int runBit = fh & n;
						Node<K,V> lastRun = f;
						for (Node<K,V> p = f.next; p != null; p = p.next) {
							int b = p.hash & n;
							if (b != runBit) {
								runBit = b;
								lastRun = p;
							}
						}
						
						if (runBit == 0) {
							ln = lastRun;
							hn = null;
						} else {
							hn = lastRun;
							ln = null;
						}
						
						for (Node<K,V> p = f; p != lastRun; p = p.next) {
							int ph = p.hash; K pk = p.key; V pv = p.val;
							if ((ph & n) == 0) {
								ln = new Node<K,V>(ph, pk, pv, ln);
							} else {
								hn = new Node<K,V>(ph, pk, pv, hn);
							}
						}
						setTabAt(nextTab, i, ln);
						setTabAt(nextTab, i + n, hn);
						setTabAt(tab, i, fwd);
						advance = true;
					} else if (f instanceof TreeBin) {
						TreeBin<K,V> t = (TreeBin<K,V>)f;
						TreeNode<K,V> lo = null, loTail = null;
						TreeNode<K,V> hi = null, hiTail = null;
						int lc = 0, hc = 0;
						for (Node<K,V> e = t.first; e != null; e = e.next) {
							int h = e.hash;
							TreeNode<K,V> p = new TreeNode<K,V>(h, e.key, e.val, null, null);
							if ((h & n) == 0) {
								if ((p.prev = loTail) == null){
									lo = p;
								} else {
									loTail.next = p;
								}
								loTail = p;
								++lc;
							} else {
								if ((p.prev = hiTail) == null) {
									hi = p;
								} else {
									hiTail.next = p;
								}
								hiTail = p;
								++hc;
							}
						}
						
						ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin<K,V>(lo) : t;
						hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin<K,V>(hi) : t;
						setTabAt(nextTab, i, ln);
						setTabAt(nextTab, i + n, hn);
						setTabAt(tab, i, fwd);
						advance = true;
					}
				}
			}
		}
	}
}


##################################   get过程。  ########################################
// get是没有锁的。
public V get(Object key) {
	Node<K,V>[] tab; 
	Node<K,V> e, p; 
	
	// n：数组长度，eh：节点的hash值，
	int n, eh; K ek;
	
	int h = spread(key.hashCode());
	
	// 把tabel赋值给tab。把长度赋值给n。e为获取对应key的节点。
	if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) {
		// 直接返回。
		if ((eh = e.hash) == h) {
			if ((ek = e.key) == key || (ek != null && key.equals(ek))) {
				return e.val;
			}
		// 如果头结点的hash小于0，说明正在扩容，或者该位置是红黑树。
		} else if (eh < 0) {
			return (p = e.find(h, key)) != null ? p.val : null;
		}
		
		while ((e = e.next) != null) {
			if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
				return e.val;
			}
		}
	}
	
	return null;
}


############################################################        size()      ########################################################
/**
 *
 */
public int size() {
	long n = sumCount();
	return ((n < 0L) ? 0 : (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);
}

/**
 *
 */
final long sumCount() {
	CounterCell[] as = counterCells; CounterCell a;
	long sum = baseCount;
	if (as != null) {
		for (int i = 0; i < as.length; ++i) {
			if ((a = as[i]) != null) {
				sum += a.value;
			}
		}
	}
	return sum;
}
